{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff7e31df",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/skaiworldwide-oss/agensgraph-ai/blob/main/llama-index/examples/vector_stores/AgensgraphVectorDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80018bc3-f3fe-47ae-a579-f837fdf728a0",
   "metadata": {},
   "source": [
    "# Agensgraph vector store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ae79640",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a256f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# %pip install /path/to/llama_index_agensgraph-0.1.0-py3-none-any.whl\n",
    "%pip install llama_index simplejson llama-index-llms-azure-openai llama-index-embeddings-azure-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e67be7b-f135-4feb-827e-6585f86c4ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# In case of Azure OpenAI, set the following\n",
    "# from llama_index.core import Settings\n",
    "# from llama_index.llms.azure_openai import AzureOpenAI\n",
    "# from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "# llm = AzureOpenAI(\n",
    "#     deployment_name=\"\",\n",
    "#     model=\"\",\n",
    "#     api_key=\"\",\n",
    "#     azure_endpoint=\"\",\n",
    "#     api_version=\"\",\n",
    "# )\n",
    "# embedding = AzureOpenAIEmbedding(\n",
    "#     deployment_name=\"\",\n",
    "#     model=\"\",\n",
    "#     api_key=\"\",\n",
    "#     azure_endpoint=\"\",\n",
    "#     api_version=\"\"\n",
    "# )\n",
    "# Settings.llm = llm\n",
    "# Settings.embed_model = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f3065-3072-4588-82cb-2a852019451c",
   "metadata": {},
   "source": [
    "## Initiate Agensgraph vector wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "910d6b13-576e-47b1-96dd-eacbfe10fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index_agensgraph.vector_stores.agensgraph.base import AgensgraphVectorStore\n",
    "\n",
    "url = \"postgresql://username:password@host:port/database_name\"\n",
    "embed_dim = 1536\n",
    "\n",
    "vector_store = AgensgraphVectorStore(url=url, embedding_dimension=embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c4515-982d-4f78-b099-f70eabfae60c",
   "metadata": {},
   "source": [
    "## Load documents, build the VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "348a4c97-bbf9-4eb1-8669-079c54588fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9cd108b",
   "metadata": {},
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71729c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aecb970b-7d52-4b0b-8799-605187a01dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2ee4d4-addc-49cf-b7ae-0d6146e0f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59b91a75-0754-4ded-af05-adceda3557d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>At Interleaf, the company had added a scripting language to their software, inspired by Emacs, and made the scripting language a dialect of Lisp.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What happened at interleaf?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5795fc-f517-47a1-ac8a-b5299860e5cd",
   "metadata": {},
   "source": [
    "## Hybrid search\n",
    "\n",
    "Hybrid search uses a combination of keyword and vector search\n",
    "In order to use hybrid search, you need to set the `hybrid_search` to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e737d4-8945-469f-a167-37ec8537b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_hybrid = AgensgraphVectorStore(url=url, embedding_dimension=embed_dim, hybrid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a17ead34-20d2-4610-9167-9d73675f4d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Interleaf was a company that made software for creating documents. Despite having smart people and impressive technology, it was eventually crushed by the exponential growth in the power of commodity processors in the 1990s. Inspired by Emacs, Interleaf had added a scripting language to their software, making it a dialect of Lisp.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_hybrid\n",
    ")\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What happened at interleaf?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30dd545-7a0e-44a5-aeb7-3eef9312c538",
   "metadata": {},
   "source": [
    "## Load existing vector index\n",
    "\n",
    "In order to connect to an existing vector index, you need to define the `index_name` and `text_node_property` parameters:\n",
    "\n",
    "- index_name: name of the existing vector index (default is `vector`)\n",
    "- text_node_property: name of the property that containt the text value (default is `text`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "872deaed-2fc8-48ba-be52-aae9b260508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"existing_index\"\n",
    "text_node_property = \"text\"\n",
    "existing_vector = AgensgraphVectorStore(\n",
    "    url,\n",
    "    embed_dim,\n",
    "    index_name=index_name,\n",
    "    text_node_property=text_node_property,\n",
    ")\n",
    "\n",
    "loaded_index = VectorStoreIndex.from_vector_store(existing_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e286e74-6c3c-43f6-a887-70016740a4f8",
   "metadata": {},
   "source": [
    "## Customizing responses\n",
    "\n",
    "You can customize the retrieved information from the knowledge graph using the `retrieval_query` parameter.\n",
    "\n",
    "The retrieval query must return the following four columns:\n",
    "\n",
    "* text:str - The text of the returned document\n",
    "* score:str - similarity score\n",
    "* id:str - node id\n",
    "* metadata: Dict - dictionary with additional metadata (must contain `_node_type` and `_node_content` keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c418367-ac82-4a53-9963-9cd6c190bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_query = (\n",
    "    \"RETURN 'Interleaf hired Tomaz' AS text, score, node.id AS id, \"\n",
    "    \"{{author: 'Tomaz', _node_type:node._node_type, _node_content:node._node_content}} AS metadata\"\n",
    ")\n",
    "vector_retrieval = AgensgraphVectorStore(\n",
    "    url, embed_dim, retrieval_query=retrieval_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef46046e-8c71-47ec-a948-96201a48a81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Interleaf hired Tomaz.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_index = VectorStoreIndex.from_vector_store(\n",
    "    vector_retrieval\n",
    ").as_query_engine()\n",
    "response = loaded_index.query(\"What happened at interleaf?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (agensgraph)",
   "language": "python",
   "name": "agensgraph-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
